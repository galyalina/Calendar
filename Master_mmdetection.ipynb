{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/galyalina/Calendar/blob/master/Master_mmdetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgHANbxqWJPa"
      },
      "source": [
        "## **Training RepPoints on Toulouse dataset**\n",
        "\n",
        "### **Overview**\n",
        "This notebook install all the required libraries for Reppoint operation\n",
        "\n",
        "### **Our Implementation**\n",
        "Folked from https://github.com/microsoft/RepPoints\n",
        "\n",
        "### **Our Data**\n",
        "\n",
        "Source: http://rs.ipb.uni-bonn.de/data/semcity-toulouse/\n",
        "\n",
        "Preprocessing steps:\n",
        "\n",
        "1.   Crop images to 460px square images\n",
        "2.   Generate bboxes from building segmantation masks\n",
        "3.   Add to coco format json\n",
        "4.   Dataset storage: \n",
        "\n",
        "### **Our Model**\n",
        "\n",
        "TODO describe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzX6zB3HQTLG"
      },
      "source": [
        "#Mount dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F2i6AKwCiNU",
        "outputId": "53d197b9-85a5-4b06-e1c7-a145072886af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOASdJrkE5Y5",
        "outputId": "70045008-1686-4e87-d1be-89ff6e30720a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lrwxrwxrwx 1 root root   22 Feb  1 14:25 \u001b[01;36mcuda\u001b[0m -> \u001b[01;34m/etc/alternatives/cuda\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4096 Feb  1 14:17 \u001b[01;34mcuda-10.0\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4096 Feb  1 14:20 \u001b[01;34mcuda-10.1\u001b[0m/\n",
            "lrwxrwxrwx 1 root root   25 Feb  1 14:25 \u001b[01;36mcuda-11\u001b[0m -> \u001b[01;34m/etc/alternatives/cuda-11\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4096 Feb  1 14:22 \u001b[01;34mcuda-11.0\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4096 Feb  1 14:24 \u001b[01;34mcuda-11.1\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "%ls -l /usr/local | grep cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCbOmE7x8jQ_",
        "outputId": "cd455b65-e882-4e88-d404-4c61f4eb2473"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n",
            "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Copyright (C) 2017 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check nvcc version\n",
        "!nvcc -V\n",
        "# Check GCC version\n",
        "!gcc --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGjDLHKYvkfZ"
      },
      "source": [
        "# Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiJW1uMGFgjO",
        "outputId": "9a8e8240-4a81-4af1-ea2c-353e2897c5a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mmdetection'...\n",
            "remote: Enumerating objects: 23053, done.\u001b[K\n",
            "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 23053 (delta 12), reused 37 (delta 10), pack-reused 23013\u001b[K\n",
            "Receiving objects: 100% (23053/23053), 25.95 MiB | 13.98 MiB/s, done.\n",
            "Resolving deltas: 100% (16178/16178), done.\n",
            "/content/mmdetection\n"
          ]
        }
      ],
      "source": [
        "# Get code\n",
        "!rm -rf mmdetection\n",
        "!git clone https://github.com/galyalina/mmdetection.git\n",
        "%cd mmdetection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sKFwimpM8UPF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b48c1bbe-695f-4ca1-b385-c9ca4f345589"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/index.html\n",
            "Collecting mmcv-full==1.4.0\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/mmcv_full-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (58.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 58.0 MB 16.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.4.0) (4.1.2.30)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.4.0) (1.21.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.4.0) (21.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.4.0) (7.1.2)\n",
            "Collecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.4.0) (3.13)\n",
            "Collecting yapf\n",
            "  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n",
            "\u001b[K     |████████████████████████████████| 190 kB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mmcv-full==1.4.0) (3.0.7)\n",
            "Installing collected packages: yapf, addict, mmcv-full\n",
            "Successfully installed addict-2.4.0 mmcv-full-1.4.0 yapf-0.32.0\n",
            "Obtaining file:///content/mmdetection\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmdet==2.21.0) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmdet==2.21.0) (1.21.5)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from mmdet==2.21.0) (2.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mmdet==2.21.0) (1.15.0)\n",
            "Collecting terminaltables\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.21.0) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.21.0) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.21.0) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.21.0) (0.11.0)\n",
            "Installing collected packages: terminaltables, mmdet\n",
            "  Running setup.py develop for mmdet\n",
            "Successfully installed mmdet-2.21.0 terminaltables-3.1.10\n",
            "Collecting affine==2.3.0\n",
            "  Downloading affine-2.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting attrs==21.2.0\n",
            "  Downloading attrs-21.2.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi==2021.10.8 in /usr/local/lib/python3.7/dist-packages (from -r requirements/lydorn_utils.txt (line 3)) (2021.10.8)\n",
            "Collecting click==8.0.3\n",
            "  Downloading click-8.0.3-py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 6.2 MB/s \n",
            "\u001b[?25hCollecting click-plugins==1.1.1\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting cligj==0.7.2\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Requirement already satisfied: cycler==0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements/lydorn_utils.txt (line 7)) (0.11.0)\n",
            "Requirement already satisfied: descartes==1.1.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements/lydorn_utils.txt (line 8)) (1.1.0)\n",
            "Requirement already satisfied: dill==0.3.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements/lydorn_utils.txt (line 9)) (0.3.4)\n",
            "Collecting Fiona==1.8.20\n",
            "  Downloading Fiona-1.8.20-cp37-cp37m-manylinux1_x86_64.whl (15.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.4 MB 58.7 MB/s \n",
            "\u001b[?25hCollecting fonttools==4.28.2\n",
            "  Downloading fonttools-4.28.2-py3-none-any.whl (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 59.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: GDAL in /usr/local/lib/python3.7/dist-packages (from -r requirements/lydorn_utils.txt (line 12)) (2.2.2)\n",
            "Collecting imageio==2.12.0\n",
            "  Downloading imageio-2.12.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 59.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib==1.1.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements/lydorn_utils.txt (line 14)) (1.1.0)\n",
            "Collecting jsmin==3.0.0\n",
            "  Downloading jsmin-3.0.0.tar.gz (11 kB)\n",
            "Requirement already satisfied: kiwisolver==1.3.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements/lydorn_utils.txt (line 16)) (1.3.2)\n",
            "Collecting matplotlib==3.5.0\n",
            "  Downloading matplotlib-3.5.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.2 MB 36.5 MB/s \n",
            "\u001b[?25hCollecting mkl-fft==1.3.1\n",
            "  Downloading mkl_fft-1.3.1-11-cp37-cp37m-manylinux2014_x86_64.whl (241 kB)\n",
            "\u001b[K     |████████████████████████████████| 241 kB 79.7 MB/s \n",
            "\u001b[?25hCollecting mkl-service==2.4.0\n",
            "  Downloading mkl_service-2.4.0-11-cp37-cp37m-manylinux2014_x86_64.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess==0.70.12.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements/lydorn_utils.txt (line 20)) (0.70.12.2)\n",
            "Collecting munch==2.5.0\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: networkx==2.6.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements/lydorn_utils.txt (line 22)) (2.6.3)\n",
            "Collecting numpy==1.21.4\n",
            "  Downloading numpy-1.21.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 30.7 MB/s \n",
            "\u001b[?25hCollecting overpy==0.6\n",
            "  Downloading overpy-0.6.tar.gz (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging==21.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements/lydorn_utils.txt (line 25)) (21.3)\n",
            "Collecting Pillow==8.4.0\n",
            "  Downloading Pillow-8.4.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 71.2 MB/s \n",
            "\u001b[?25hCollecting pyparsing==3.0.6\n",
            "  Downloading pyparsing-3.0.6-py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 9.3 MB/s \n",
            "\u001b[?25hCollecting pyproj\n",
            "  Downloading pyproj-3.2.1-cp37-cp37m-manylinux2010_x86_64.whl (6.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 93.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements/lydorn_utils.txt (line 29)) (2.8.2)\n",
            "Requirement already satisfied: PyWavelets==1.2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements/lydorn_utils.txt (line 30)) (1.2.0)\n",
            "Collecting rasterio==1.2.10\n",
            "  Downloading rasterio-1.2.10-cp37-cp37m-manylinux1_x86_64.whl (19.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.3 MB 83.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image==0.18.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements/lydorn_utils.txt (line 32)) (0.18.3)\n",
            "Collecting scikit-learn==1.0.1\n",
            "  Downloading scikit_learn-1.0.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.2 MB 1.1 MB/s \n",
            "\u001b[?25hCollecting scipy==1.7.2\n",
            "  Downloading scipy-1.7.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.2 MB 42 kB/s \n",
            "\u001b[?25hCollecting setuptools-scm==6.3.2\n",
            "  Downloading setuptools_scm-6.3.2-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: Shapely==1.8.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements/lydorn_utils.txt (line 36)) (1.8.0)\n",
            "Requirement already satisfied: sklearn==0.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements/lydorn_utils.txt (line 37)) (0.0)\n",
            "Collecting snuggs==1.4.7\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Collecting threadpoolctl==3.0.0\n",
            "  Downloading threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tifffile==2021.11.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements/lydorn_utils.txt (line 40)) (2021.11.2)\n",
            "Collecting tomli==1.2.2\n",
            "  Downloading tomli-1.2.2-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: tqdm==4.62.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements/lydorn_utils.txt (line 42)) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click==8.0.3->-r requirements/lydorn_utils.txt (line 4)) (4.11.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from Fiona==1.8.20->-r requirements/lydorn_utils.txt (line 10)) (57.4.0)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from Fiona==1.8.20->-r requirements/lydorn_utils.txt (line 10)) (1.15.0)\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.7/dist-packages (from mkl-fft==1.3.1->-r requirements/lydorn_utils.txt (line 18)) (2019.0)\n",
            "Collecting dpcpp_cpp_rt\n",
            "  Downloading dpcpp_cpp_rt-2022.0.2-py2.py3-none-manylinux1_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 20.7 MB/s \n",
            "\u001b[?25hCollecting intel-cmplr-lib-rt==2022.0.2\n",
            "  Downloading intel_cmplr_lib_rt-2022.0.2-py2.py3-none-manylinux1_x86_64.whl (33.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 33.5 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: intel-openmp==2022.0.2 in /usr/local/lib/python3.7/dist-packages (from dpcpp_cpp_rt->mkl-fft==1.3.1->-r requirements/lydorn_utils.txt (line 18)) (2022.0.2)\n",
            "Collecting intel-opencl-rt==2022.0.2\n",
            "  Downloading intel_opencl_rt-2022.0.2-py2.py3-none-manylinux1_x86_64.whl (228.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 228.4 MB 23 kB/s \n",
            "\u001b[?25hCollecting intel-cmplr-lic-rt==2022.0.2\n",
            "  Downloading intel_cmplr_lic_rt-2022.0.2-py2.py3-none-manylinux1_x86_64.whl (18 kB)\n",
            "Collecting tbb==2021.*\n",
            "  Downloading tbb-2021.5.1-py2.py3-none-manylinux1_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 84.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click==8.0.3->-r requirements/lydorn_utils.txt (line 4)) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click==8.0.3->-r requirements/lydorn_utils.txt (line 4)) (3.10.0.2)\n",
            "Building wheels for collected packages: jsmin, overpy\n",
            "  Building wheel for jsmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsmin: filename=jsmin-3.0.0-py3-none-any.whl size=13895 sha256=e639ff52474f66d790c5f47aa453357c444a47fc78a2df6e42b600a06def8a53\n",
            "  Stored in directory: /root/.cache/pip/wheels/aa/57/73/60e594ac2b8609a7fc2b1592d16b02d88fef3781392e13f5e6\n",
            "  Building wheel for overpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overpy: filename=overpy-0.6-py3-none-any.whl size=14106 sha256=1c0d08dc01b8d157d0544d8754755380a7e0b48caf38c63027dce07377766b9f\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/d3/0e/090c6914956cc37881fc914101d2a952c0da8e66fc86dc6a31\n",
            "Successfully built jsmin overpy\n",
            "Installing collected packages: pyparsing, tomli, tbb, numpy, intel-cmplr-lic-rt, threadpoolctl, setuptools-scm, scipy, Pillow, intel-opencl-rt, intel-cmplr-lib-rt, fonttools, click, snuggs, scikit-learn, munch, matplotlib, imageio, dpcpp-cpp-rt, cligj, click-plugins, attrs, affine, rasterio, pyproj, overpy, mkl-service, mkl-fft, jsmin, Fiona\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.7\n",
            "    Uninstalling pyparsing-3.0.7:\n",
            "      Successfully uninstalled pyparsing-3.0.7\n",
            "  Attempting uninstall: tomli\n",
            "    Found existing installation: tomli 2.0.1\n",
            "    Uninstalling tomli-2.0.1:\n",
            "      Successfully uninstalled tomli-2.0.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.5\n",
            "    Uninstalling numpy-1.21.5:\n",
            "      Successfully uninstalled numpy-1.21.5\n",
            "  Attempting uninstall: threadpoolctl\n",
            "    Found existing installation: threadpoolctl 3.1.0\n",
            "    Uninstalling threadpoolctl-3.1.0:\n",
            "      Successfully uninstalled threadpoolctl-3.1.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 21.4.0\n",
            "    Uninstalling attrs-21.4.0:\n",
            "      Successfully uninstalled attrs-21.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.0.3 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Fiona-1.8.20 Pillow-8.4.0 affine-2.3.0 attrs-21.2.0 click-8.0.3 click-plugins-1.1.1 cligj-0.7.2 dpcpp-cpp-rt-2022.0.2 fonttools-4.28.2 imageio-2.12.0 intel-cmplr-lib-rt-2022.0.2 intel-cmplr-lic-rt-2022.0.2 intel-opencl-rt-2022.0.2 jsmin-3.0.0 matplotlib-3.5.0 mkl-fft-1.3.1 mkl-service-2.4.0 munch-2.5.0 numpy-1.21.4 overpy-0.6 pyparsing-3.0.6 pyproj-3.2.1 rasterio-1.2.10 scikit-learn-1.0.1 scipy-1.7.2 setuptools-scm-6.3.2 snuggs-1.4.7 tbb-2021.5.1 threadpoolctl-3.0.0 tomli-1.2.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./libs/lydorn_utils-0.0.1-py3-none-any.whl\n",
            "Installing collected packages: lydorn-utils\n",
            "Successfully installed lydorn-utils-0.0.1\n"
          ]
        }
      ],
      "source": [
        "# install dependencies: (use cu101 because colab has CUDA 10.1)\n",
        "# !pip install -U torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# install mmcv-full thus we could use CUDA operators\n",
        "!pip install mmcv-full==1.4.0 -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/index.html\n",
        "\n",
        "# Install mmdetection\n",
        "!pip install -e .\n",
        "!pip install -r requirements/lydorn_utils.txt\n",
        "!pip install libs/lydorn_utils-0.0.1-py3-none-any.whl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlVlrUsIitgx"
      },
      "source": [
        "#!Restart Runtime!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5Qe9QUMvc8k"
      },
      "source": [
        "# Alternative: install Anaconda env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBM-UMuE-1Ar"
      },
      "outputs": [],
      "source": [
        "# %%bash\n",
        "# git clone https://github.com/galyalina/mmdetection.git\n",
        "# cd mmdetection\n",
        "# ls\n",
        "# bash setup-colab.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwLSPV7TD-JF"
      },
      "outputs": [],
      "source": [
        "# %%bash\n",
        "# python setup.py develop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBU7CQJiQlNU"
      },
      "source": [
        "#Check installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ejopew78ycw",
        "outputId": "991503c1-1f17-4f36-ab64-13cdd67eb001"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111 True\n",
            "2.21.0\n",
            "11.1\n",
            "GCC 7.3\n"
          ]
        }
      ],
      "source": [
        "# Check Pytorch installation\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "# Check MMDetection installation\n",
        "import mmdet\n",
        "print(mmdet.__version__)\n",
        "\n",
        "# Check mmcv installation\n",
        "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
        "print(get_compiling_cuda_version())\n",
        "print(get_compiler_version())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6t-Exd8s9S1"
      },
      "source": [
        "#Link data folders from Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UIKn5QxkHjUu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "148bc7fc-0193-4a5c-8cc1-8a495cdaeb66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/mmdetection/work_dirs' -> '/content/drive/My Drive/MasterThesis/work_dirs'\n",
            "'/content/mmdetection/experiments' -> '/content/drive/My Drive/MasterThesis/experiments'\n"
          ]
        }
      ],
      "source": [
        "!ln -s \"/content/drive/My Drive/MasterThesis/data\" \"/content/mmdetection/data\"\n",
        "!ln -sv \"/content/drive/My Drive/MasterThesis/work_dirs\" \"/content/mmdetection/work_dirs\"\n",
        "!ln -sv \"/content/drive/My Drive/MasterThesis/experiments\" \"/content/mmdetection/experiments\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualize network\n",
        "\n"
      ],
      "metadata": {
        "id": "GhwUuuYdZjyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5pALLn9ZjXu",
        "outputId": "8829ba1f-9015-42ab-9f06-1ce493e7884c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Add visualization"
      ],
      "metadata": {
        "id": "xsTIgfHjE3S0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Stephenfang51/mmdetection_visualize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFtAnDXkE2iq",
        "outputId": "b3da3a44-cd32-4ca2-e500-8eda4fb477b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 0: cd: /root/content: No such file or directory\n",
            "Cloning into 'mmdetection_visualize'...\n",
            "remote: Enumerating objects: 53, done.\u001b[K\n",
            "remote: Total 53 (delta 0), reused 0 (delta 0), pack-reused 53\u001b[K\n",
            "Unpacking objects: 100% (53/53), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp mmdetection_visualize/voc_eval_visualize.py tools/\n",
        "!cp mmdetection_visualize/mean_ap_visualize.py mmdet/core/evaluation/"
      ],
      "metadata": {
        "id": "AMEZFdf1E2rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp work_dirs/reppoints_moment_r101_fpn_gn-neck+head_2x_toulouse/20211125_095409.log.json mmdetection_visualize/json/"
      ],
      "metadata": {
        "id": "nXp_why7F20q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67777125-4a20-4dd9-ee5d-23b4bc6461ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot create regular file 'mmdetection_visualize/json/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash \n",
        "cd mmdetection/mmdetection_visualize\n",
        "python visualize.py json/20211125_095409.log.json"
      ],
      "metadata": {
        "id": "4DhUcxp9HEL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate zeven dataset"
      ],
      "metadata": {
        "id": "qrxLmaHk-CDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash      \n",
        "python tools/test.py \\\n",
        "    work_dirs/reppoints_moment_r101_fpn_gn-neck+head_2x_toulouse/test_reppoints_moment_r101_fpn_gn-neck+head_2x_toulouse.py \\\n",
        "    work_dirs/reppoints_moment_r101_fpn_gn-neck+head_2x_toulouse/epoch_24.pth \\\n",
        "    --eval bbox\\\n",
        "    --show-dir data/brauschweig/results \\"
      ],
      "metadata": {
        "id": "CO9amSRK-Mdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Zeven labled result\n",
        "\n",
        "loading annotations into memory...\n",
        "Done (t=0.01s)\n",
        "creating index...\n",
        "index created!\n",
        "load checkpoint from local path: work_dirs/reppoints_moment_r101_fpn_gn-neck+head_2x_toulouse/epoch_24.pth\n",
        "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 112/112, 11.1 task/s, elapsed: 10s, ETA:     0s\n",
        "Evaluating bbox...\n",
        "Loading and preparing results...\n",
        "DONE (t=0.01s)\n",
        "creating index...\n",
        "index created!\n",
        "Running per image evaluation...\n",
        "Evaluate annotation type *bbox*\n",
        "DONE (t=8.90s).\n",
        "Accumulating evaluation results...\n",
        "DONE (t=0.24s).\n",
        " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.430\n",
        " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.726\n",
        " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.452\n",
        " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.361\n",
        " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.550\n",
        " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.445\n",
        " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.529\n",
        " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.529\n",
        " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.529\n",
        " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.469\n",
        " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.639\n",
        " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.629"
      ],
      "metadata": {
        "id": "J5te_OqJIiFe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCX8AGFvZbhd"
      },
      "source": [
        "#Train model, uncomment for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "k9aUG3DmZcl3"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "# source activate openmmlab\n",
        "\n",
        "#Add resume_from = 'work_dirs/reppoints_moment_r101_fpn_gn-neck+head_2x_toulouse/epoch_23.pth' for resuming training\n",
        "#RepPoints\n",
        "bash tools/dist_train.sh configs/reppoints_toulouse/reppoints_moment_r101_fpn_gn-neck+head_2x_toulouse.py 1 &>> work_dirs/reppoints_moment_r101_fpn_gn-neck+head_2x_toulouse/log.txt\n",
        "#RepPoints\n",
        "# bash tools/dist_train.sh configs/reppoints/reppoints_moment_r101_fpn_dconv_c3-c5_gn-neck+head_2x_toulouse.py 1 &>> work_dirs/reppoints_moment_r101_fpn_dconv_c3-c5_gn-neck+head_2x_toulouse/log.txt\n",
        "#YOLO\n",
        "# bash tools/dist_train.sh configs/yolo/yolov3_d53_320_273e_toulouse.py 1 &>> work_dirs/yolov3_d53_320_273e_toulouse/log.txt\n",
        "\n",
        "#Faster RCNN\n",
        "# bash tools/dist_train.sh configs/faster_rcnn_toulouse/faster_rcnn_r101_fpn_2x_toulouse.py 1 &>> work_dirs/faster_rcnn_r101_fpn_2x_toulouse/log.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard --logdir faster_rcnn_toulouse/tf_logs"
      ],
      "metadata": {
        "id": "VQpHQJyZcLkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F852unbPABdU"
      },
      "source": [
        "#Print predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gu_B02mKsNXA"
      },
      "outputs": [],
      "source": [
        "#Required for slicing the image \n",
        "!pip install sahi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash \n",
        "python tools/analysis_tools/get_flops.py 'work_dirs/reppoints_v1_r101_fpn_giou_mstrain_2x_toulouse/reppoints_v1_r101_fpn_giou_mstrain_2x_toulouse.py'\n",
        "# python tools/analysis_tools/get_flops.py 'work_dirs/reppoints_moment_r101_fpn_gn-neck+head_2x_toulouse/reppoints_moment_r101_fpn_gn-neck+head_2x_toulouse.py' "
      ],
      "metadata": {
        "id": "Sihj0PJTcrVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLdd-j_I81B8"
      },
      "outputs": [],
      "source": [
        "from mmdet.apis import inference_detector, init_detector\n",
        "from mmdet.apis import show_result_pyplot\n",
        "import os\n",
        "import mmcv\n",
        "import numpy as np\n",
        "import lydorn_utils.geo_utils as utils\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from PIL import Image, ImageDraw\n",
        "from sahi.model import MmdetDetectionModel\n",
        "from sahi.predict import get_prediction, get_sliced_prediction, predict\n",
        "from sahi.utils.cv import visualize_object_predictions\n",
        "\n",
        "# Choose to use a config and initialize the detector\n",
        "config = 'mmdetection/work_dirs/reppoints_moment_r101_fpn_gn-neck+head_2x_toulouse/reppoints_moment_r101_fpn_gn-neck+head_2x_toulouse.py'\n",
        "# Setup a checkpoint file to load\n",
        "checkpoint = 'mmdetection/work_dirs/reppoints_moment_r101_fpn_gn-neck+head_2x_toulouse/checkpoint_24.pth'\n",
        "# initialize the detector\n",
        "model = init_detector(config, checkpoint, device='cuda:0')\n",
        "detection_model = MmdetDetectionModel(\n",
        "    model_path=checkpoint,\n",
        "    config_path=config,\n",
        "    confidence_threshold=0.4,\n",
        "    device='cuda' # or 'cpu'\n",
        "  )\n",
        "\n",
        "# test_directory = 'mmdetection/data/niedersachsen/brauschwieg/rgb_reduced/'\n",
        "# prediction_directory = 'mmdetection/data/niedersachsen/brauschwieg/predictions/sliced_460_px/'\n",
        "# osm_and_prediction_directory = 'mmdetection/data/niedersachsen/brauschwieg/osm_and_predictions/'\n",
        "\n",
        "test_directory = 'mmdetection/data/niedersachsen/zeven/rgb_reduced/'\n",
        "prediction_directory = 'mmdetection/data/niedersachsen/zeven/predictions/sliced_460/'\n",
        "osm_and_prediction_directory = 'mmdetection/data/niedersachsen/zeven/osm_and_predictions/'\n",
        "\n",
        "# test_directory = 'mmdetection/data/toulouse/unlabled/'\n",
        "# prediction_directory = 'mmdetection/data/toulouse/predictions/sliced_460_px/'\n",
        "# osm_and_prediction_directory = 'mmdetection/data/toulouse/osm_and_predictions/'\n",
        "\n",
        "def get_osm_segmentation(original_dir, predicted_dir, image_name, destination_dir):\n",
        "    mask = Image.open(predicted_dir + image_name)\n",
        "    print(predicted_dir + image_name)\n",
        "    mask_draw = ImageDraw.Draw(mask)\n",
        "    str_proj_EPSG_25832 = \"PROJCS[\\\"ETRS89 / UTM zone 32N\\\",GEOGCS[\\\"ETRS89\\\",DATUM[\\\"European_Terrestrial_Reference_System_1989\\\",SPHEROID[\\\"GRS 1980\\\",6378137,298.257222101,AUTHORITY[\\\"EPSG\\\",\\\"7019\\\"]],TOWGS84[0,0,0,0,0,0,0],AUTHORITY[\\\"EPSG\\\",\\\"6258\\\"]],PRIMEM[\\\"Greenwich\\\",0,AUTHORITY[\\\"EPSG\\\",\\\"8901\\\"]],UNIT[\\\"degree\\\",0.0174532925199433,AUTHORITY[\\\"EPSG\\\",\\\"9122\\\"]],AUTHORITY[\\\"EPSG\\\",\\\"4258\\\"]],PROJECTION[\\\"Transverse_Mercator\\\"],PARAMETER[\\\"latitude_of_origin\\\",0],PARAMETER[\\\"central_meridian\\\",9],PARAMETER[\\\"scale_factor\\\",0.9996],PARAMETER[\\\"false_easting\\\",500000],PARAMETER[\\\"false_northing\\\",0],UNIT[\\\"metre\\\",1,AUTHORITY[\\\"EPSG\\\",\\\"9001\\\"]],AXIS[\\\"Easting\\\",EAST],AXIS[\\\"Northing\\\",NORTH],AUTHORITY[\\\"EPSG\\\",\\\"25832\\\"]]\"\n",
        "    poligons = utils.get_polygons_from_osm(original_dir + image_name,\n",
        "                                           tag=\"building\",\n",
        "                                           ij_coords=False,\n",
        "                                           specific_projection=str_proj_EPSG_25832)\n",
        "    for p in poligons:\n",
        "      result = list(map(tuple, np.array(p).astype(int)))\n",
        "      mask_draw.polygon(result, outline='#ff00ff')\n",
        "      bbox = p[:, 0].min(), p[:, 0].max(), p[:, 1].min(), p[:, 1].max()\n",
        "      mask_draw.rectangle([(bbox[0], bbox[2]), (bbox[1], bbox[3])], outline='#ff00ff', width=2)\n",
        "    mask.save(destination_dir + image_name)\n",
        "    return destination_dir + image_name\n",
        "\n",
        "\n",
        "def store_predictions_to_file(original_image, results, output):\n",
        "    model.show_result(original_image,\n",
        "                    results,\n",
        "                    score_thr=0.4,\n",
        "                    bbox_color=(00, 255, 00),\n",
        "                    text_color=(00, 255, 00),\n",
        "                    mask_color=None,\n",
        "                    thickness=2,\n",
        "                    font_size=1,\n",
        "                    win_name='',\n",
        "                    show=False,\n",
        "                    wait_time=0,\n",
        "                    out_file=output)\n",
        "\n",
        "for filename in os.listdir(test_directory):\n",
        "    if (filename.endswith(\".tif\") or filename.endswith(\".tiff\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\")) and '_detection' not in filename: \n",
        "        # result = inference_detector(model, test_directory+filename)\n",
        "        # result_sliced = get_sliced_prediction(\n",
        "        #       test_directory+filename,\n",
        "        #       detection_model, \n",
        "        #       slice_width=460, \n",
        "        #       slice_height=460,\n",
        "        #       overlap_height_ratio = 0,\n",
        "        #       overlap_width_ratio = 0\n",
        "        # )\n",
        "        # result = detection_model._create_original_predictions_from_object_prediction_list(result_sliced.object_prediction_list)\n",
        "        # store_predictions_to_file(test_directory+filename, result, prediction_directory+filename)\n",
        "\n",
        "        osm_mask_path = get_osm_segmentation(test_directory, prediction_directory, filename, osm_and_prediction_directory)\n",
        "        # store_predictions_to_file(osm_and_prediction_directory+filename, result, osm_and_prediction_directory+filename)\n",
        "        # break\n",
        "    else:\n",
        "        continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3CEsCEfZZf2"
      },
      "source": [
        "Test trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irjBQPZnbmhQ"
      },
      "outputs": [],
      "source": [
        "while True:pass"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PYTORCH TO ONNX (EXPERIMENTAL)"
      ],
      "metadata": {
        "id": "udYDdsOnwKvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python tools/deployment/pytorch2onnx.py \\\n",
        "    configs/yolo/yolov3_d53_mstrain-608_273e_coco.py \\\n",
        "    checkpoints/yolo/yolov3_d53_mstrain-608_273e_coco.pth \\\n",
        "    --output-file checkpoints/yolo/yolov3_d53_mstrain-608_273e_coco.onnx \\\n",
        "    --input-img demo/demo.jpg \\\n",
        "    --test-img tests/data/color.jpg \\\n",
        "    --shape 608 608 \\\n",
        "    --show \\\n",
        "    --verify \\\n",
        "    --dynamic-export \\\n",
        "    --cfg-options \\\n",
        "      model.test_cfg.deploy_nms_pre=-1 \\"
      ],
      "metadata": {
        "id": "ef9sBxtowKFC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "F852unbPABdU"
      ],
      "machine_shape": "hm",
      "name": "Master-mmdetection",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}